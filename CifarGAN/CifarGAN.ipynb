{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "img_size = 32\n",
    "batch_size = 128\n",
    "\n",
    "# Use the custom dataset in the data loader\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dset.CIFAR10(\n",
    "        \"../../data/cifar10\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "# Use the custom dataset in the data loader\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dset.CIFAR10(\n",
    "        \"../../data/cifar10\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "# Train data example\n",
    "train_dataloader.batch_size\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "img = img.permute(1, 2, 0)  # Change the shape to (32, 32, 3)\n",
    "img = (img + 1) / 2  # Adjust the values to [0, 1] range\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# Test data example\n",
    "test_dataloader.batch_size\n",
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "print(f\"Feature batch shape: {test_features.size()}\")\n",
    "print(f\"Labels batch shape: {test_labels.size()}\")\n",
    "img = test_features[0].squeeze()\n",
    "label = test_labels[0]\n",
    "img = img.permute(1, 2, 0)  # Change the shape to (32, 32, 3)\n",
    "img = (img + 1) / 2  # Adjust the values to [0, 1] range\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 32 x 32\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 16 x 16\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(256, 1, 4, 1, 0, bias=False),\n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(100, 256, 4, 1, 0, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "# Create Discriminator and Generator instances on CUDA device\n",
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "# Initialize optimizer for Discriminator and Generator\n",
    "optimizerD = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "# Print info about the models\n",
    "print(D)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "num_epochs = 15\n",
    "# Training Loop\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # Train with all-real batch\n",
    "        D.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), 1, dtype=torch.float32,device=device)\n",
    "        output = D(real_cpu).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        # Train with all-fake batch\n",
    "        noise = torch.randn(b_size, 100, 1, 1, device=device)\n",
    "        fake = G(noise)\n",
    "        label.fill_(0)\n",
    "        output = D(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        # Update G network\n",
    "        G.zero_grad()\n",
    "        label.fill_(1)  # fake labels are real for generator cost\n",
    "        output = D(fake).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch}/{num_epochs}][{i}/{len(train_dataloader)}]\\t\"\n",
    "                  f\"Loss_D: {errD.item():.4f}\\tLoss_G: {errG.item():.4f}\\t\"\n",
    "                  f\"D(x): {D_x:.4f}\\tD(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}\")\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(train_dataloader) - 1)):\n",
    "            with torch.no_grad():\n",
    "                fake = G(noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            # Save the images to images folder\n",
    "\n",
    "            vutils.save_image(fake, f\"images/fake_images_{iters}.png\")\n",
    "            # Save animation\n",
    "\n",
    "        iters += 1\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "# Save the animation to a file and store it to images directory\n",
    "ani.save('images/dcgan_ani.gif', writer='imagemagick', fps=4)\n",
    "# Save the model\n",
    "torch.save(G.state_dict(), \"saved_model/generator.pth\")\n",
    "plt.figure()\n",
    "# Plot the training losses\n",
    "plt.plot(G_losses, label='Generator loss')\n",
    "plt.plot(D_losses, label='Discriminator Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
